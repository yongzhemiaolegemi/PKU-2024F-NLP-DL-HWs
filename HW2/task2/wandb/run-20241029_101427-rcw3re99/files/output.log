2024-10-29 10:14:29 - INFO - __main__ - Initializing training script
2024-10-29 10:14:29 - INFO - __main__ - Loading dataset...
2024-10-29 10:14:29 - INFO - __main__ - Loading model and tokenizer...
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Map: 100%|██████████████████████████████████████████████████████████████████████████| 1688/1688 [00:00<00:00, 12033.06 examples/s]
Map: 100%|█████████████████████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 7965.03 examples/s]
/root/HW2/task2/train.py:101: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
2024-10-29 10:14:34 - INFO - __main__ - Starting training...
  0%|                                                                                                     | 0/159 [00:00<?, ?it/s]/root/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 33%|██████████████████████████████▋                                                             | 53/159 [00:11<00:19,  5.56it/s]/root/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 1.5211, 'grad_norm': 2.9284708499908447, 'learning_rate': 4.685534591194969e-05, 'epoch': 0.19}
{'loss': 1.2896, 'grad_norm': 3.0839710235595703, 'learning_rate': 4.3710691823899376e-05, 'epoch': 0.38}
{'loss': 1.3659, 'grad_norm': 4.103024482727051, 'learning_rate': 4.0566037735849064e-05, 'epoch': 0.57}
{'loss': 1.1716, 'grad_norm': 10.793360710144043, 'learning_rate': 3.7421383647798744e-05, 'epoch': 0.75}
{'loss': 1.1148, 'grad_norm': 7.495213985443115, 'learning_rate': 3.4276729559748424e-05, 'epoch': 0.94}
  warnings.warn(                                                                                                                  
{'eval_loss': 1.109758734703064, 'eval_accuracy': 0.6115107913669064, 'eval_micro_f1': 0.6115107913669064, 'eval_macro_f1': 0.2697923213214173, 'eval_runtime': 0.3768, 'eval_samples_per_second': 368.907, 'eval_steps_per_second': 13.27, 'epoch': 1.0}
 67%|████████████████████████████████████████████████████████████▋                              | 106/159 [00:21<00:09,  5.56it/s]/root/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 1.0452, 'grad_norm': 4.826653003692627, 'learning_rate': 3.113207547169811e-05, 'epoch': 1.13}
{'loss': 1.0396, 'grad_norm': 9.815643310546875, 'learning_rate': 2.7987421383647798e-05, 'epoch': 1.32}
{'loss': 1.0272, 'grad_norm': 11.38023853302002, 'learning_rate': 2.4842767295597485e-05, 'epoch': 1.51}
{'loss': 0.9951, 'grad_norm': 6.297832489013672, 'learning_rate': 2.1698113207547172e-05, 'epoch': 1.7}
{'loss': 0.9753, 'grad_norm': 10.273711204528809, 'learning_rate': 1.8553459119496856e-05, 'epoch': 1.89}
  warnings.warn(                                                                                                                  
{'eval_loss': 0.9573471546173096, 'eval_accuracy': 0.6690647482014388, 'eval_micro_f1': 0.6690647482014388, 'eval_macro_f1': 0.3275237091675448, 'eval_runtime': 0.3789, 'eval_samples_per_second': 366.816, 'eval_steps_per_second': 13.195, 'epoch': 2.0}
100%|███████████████████████████████████████████████████████████████████████████████████████████| 159/159 [00:31<00:00,  5.56it/s]/root/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.9479, 'grad_norm': 5.979335784912109, 'learning_rate': 1.540880503144654e-05, 'epoch': 2.08}
{'loss': 0.7979, 'grad_norm': 8.346611022949219, 'learning_rate': 1.2264150943396227e-05, 'epoch': 2.26}
{'loss': 0.8099, 'grad_norm': 13.938563346862793, 'learning_rate': 9.119496855345912e-06, 'epoch': 2.45}
{'loss': 0.8167, 'grad_norm': 10.85443115234375, 'learning_rate': 5.974842767295598e-06, 'epoch': 2.64}
{'loss': 0.7206, 'grad_norm': 14.819610595703125, 'learning_rate': 2.830188679245283e-06, 'epoch': 2.83}
  warnings.warn(
100%|███████████████████████████████████████████████████████████████████████████████████████████| 159/159 [00:33<00:00,  4.72it/s]
2024-10-29 10:15:08 - INFO - __main__ - Starting evaluation...                                                                    
{'eval_loss': 0.8932028412818909, 'eval_accuracy': 0.6762589928057554, 'eval_micro_f1': 0.6762589928057554, 'eval_macro_f1': 0.3349966041244046, 'eval_runtime': 0.3982, 'eval_samples_per_second': 349.083, 'eval_steps_per_second': 12.557, 'epoch': 3.0}
{'train_runtime': 33.7023, 'train_samples_per_second': 150.257, 'train_steps_per_second': 4.718, 'train_loss': 1.0244895107341263, 'epoch': 3.0}
/root/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
100%|███████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 15.73it/s]
2024-10-29 10:15:08 - INFO - __main__ - Evaluation results: {'eval_loss': 0.8932028412818909, 'eval_accuracy': 0.6762589928057554, 'eval_micro_f1': 0.6762589928057554, 'eval_macro_f1': 0.3349966041244046, 'eval_runtime': 0.4192, 'eval_samples_per_second': 331.556, 'eval_steps_per_second': 11.926, 'epoch': 3.0}
2024-10-29 10:15:08 - INFO - __main__ - Training complete.
